---
layout: default
title:  Home
---

The game 2048 trained with DQN and PPO. Which one's better?

Source code: https://github.com/leem07/PowerOf2

Reports:
- [Proposal](proposal.html)
- [Status](status.html)
- [Final](final.html)


References Used:
- [2048 GitHub Repository](https://github.com/Quentin18/gymnasium-2048/blob/main/README.md)
- [Stable Baselines3 DQN](https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html)
- [DeepMind Technologies DQN Paper](https://arxiv.org/pdf/1312.5602)
- [Stanford 2048 Paper](https://arxiv.org/html/2507.05465v1)
- [Medium 2048 Article](https://medium.com/data-science/a-puzzle-for-ai-eb7a3cb8e599)
